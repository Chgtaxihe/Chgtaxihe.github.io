(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{564:function(t,s,a){t.exports=a.p+"assets/img/paddlepaddle使用有感_1.881d8f1a.png"},565:function(t,s,a){t.exports=a.p+"assets/img/paddlepaddle使用有感_2.11ff4cf3.png"},626:function(t,s,a){"use strict";a.r(s);var n=a(30),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("p",[t._v("今年十月份学校成立了个人工智能学院，准备在明年开始招生；估计是学校想做下教学实验，最近我的Java老师组了个AI兴趣班，也因此我接触到了PaddlePaddle。")]),t._v(" "),n("p",[t._v("先放一句总结：用PaddlePaddle，就请做好读源码准备(特别是那些想要用动态图的人)。")]),t._v(" "),n("h2",{attrs:{id:"第一印象"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第一印象"}},[t._v("#")]),t._v(" 第一印象")]),t._v(" "),n("p",[t._v("作为用过Tensorflow的苦手，PaddlePaddle上手十分容易。一是中文文档较之英文易读，二是有百度的"),n("code",[t._v("AI Studio")]),t._v('练手，这一过程还是比较"愉快"的；同时官方还给出了'),n("a",{attrs:{href:"https://paddlepaddle.org.cn/documentation/docs/zh/api_guides/X2Paddle/TensorFlow-Fluid.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("TensorFlow-Fluid常用接口对应表"),n("OutboundLink")],1),t._v("，总之，对使用过Tensorflow的用户十分之友好。")]),t._v(" "),n("h2",{attrs:{id:"深入使用"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#深入使用"}},[t._v("#")]),t._v(" 深入使用")]),t._v(" "),n("p",[t._v("我用PaddlePaddle做的第一个项目是Image Captioning任务，代码基本照抄"),n("code",[t._v("Show Attend and Tell")]),t._v("的Tensorflow版实现，这里讲下我的体验：一是绝对不能想当然，用Tensorflow的经验去套PaddlePaddle，举个例子，"),n("code",[t._v("fc")]),t._v("层(即"),n("code",[t._v("Dense")]),t._v(")里有个"),n("code",[t._v("num_flatten_dims")]),t._v("，不查文档还真就出大问题了；二是官方的使用指南不太完善，想要用预训练模型却不知道怎么导入参数，最后是翻"),n("code",[t._v("fluid.io.save_persistables")]),t._v("的源码才找到"),n("code",[t._v("load_vars")]),t._v("这个操作，并模仿源码写了个"),n("code",[t._v("predicate")]),t._v('才把参数导入进去的。三是"Bug"，'),n("code",[t._v("softmax_with_cross_entropy")]),t._v("这个函数似乎在梯度传导时有些毛病，搜索了好一番才在github的issue里找到了解决方法(顺带一提，PaddlePaddle的社区比Tensorflow差远了)。")]),t._v(" "),n("h2",{attrs:{id:"吐槽paddlepaddle动态图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#吐槽paddlepaddle动态图"}},[t._v("#")]),t._v(" 吐槽PaddlePaddle动态图")]),t._v(" "),n("p",[t._v("整个文档只有这么一个"),n("a",{attrs:{href:"https://paddlepaddle.org.cn/documentation/docs/zh/user_guides/howto/dygraph/DyGraph.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("页面"),n("OutboundLink")],1),t._v('是介绍动态图的。估计官方的意思是："想要用动态图？自己看源码去"。不说了，你们自己看看文档体会一下吧。')]),t._v(" "),n("h2",{attrs:{id:"upd-2020-05-21"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#upd-2020-05-21"}},[t._v("#")]),t._v(" UPD：2020-05-21")]),t._v(" "),n("hr"),t._v(" "),n("p",[t._v("今天研究了一下官方给的度量学习的例子，发现了一个没见过的函数"),n("code",[t._v("fluid.load()")]),t._v("，去Paddle文档一看，才发现Fluid已经更新到了1.8，这个函数是在1.7新增的。")]),t._v(" "),n("p",[t._v("先看一下文档的说明：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(564),alt:""}})]),t._v(" "),n("p",[t._v("仔细研究后发现不对：在例子的"),n("code",[t._v("finetune.py")]),t._v("里直接"),n("code",[t._v("load")]),t._v("了预训练的模型checkpoint，但finetune的模型结构与与训练的不同！按理说这种情况下加载模型应该会报错（"),n("code",[t._v("load_persistables")]),t._v("或"),n("code",[t._v("load_param")]),t._v("会报错）")]),t._v(" "),n("p",[t._v("又仔细看了一遍文档，并没有相关的说明，只好看源码。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(565),alt:""}})]),t._v(" "),n("p",[t._v("真相大白。")]),t._v(" "),n("hr"),t._v(" "),n("p",[t._v("这也是为什么我之前说如果要用Paddle，就得做好读源码的准备----Paddle的文档写的真的差。")]),t._v(" "),n("h2",{attrs:{id:"upd-2020-05-22"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#upd-2020-05-22"}},[t._v("#")]),t._v(" UPD: 2020-05-22")]),t._v(" "),n("p",[t._v("cross_entropy的bug")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("loss")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    logit "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("class_dim"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            param_attr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ParamAttr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"softmax_loss_fc_w"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            bias_attr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ParamAttr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"softmax_loss_fc_b"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    logit "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" use_cudnn"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    loss "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cross_entropy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" soft_label"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" logit\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br")])]),n("p",[n("s",[t._v("不知为什么，以上代码得到的loss居然为为负值")]),t._v("（个人猜测不是精度问题）")]),t._v(" "),n("p",[t._v("修复方式")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("loss")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    logit "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("class_dim"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            param_attr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ParamAttr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"softmax_loss_fc_w"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            bias_attr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ParamAttr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"softmax_loss_fc_b"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    loss "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax_with_cross_entropy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    logit "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fluid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" use_cudnn"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" loss"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" logit\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br")])])])}),[],!1,null,null,null);s.default=e.exports}}]);